\chapter{Results} \label{sec:study_results}

This Chapter describes all the results gathered throughout the study in a per RQ basis. This approach increase the traceability of the findings within the report as suggested by Runeson et al. \cite{case_study_software_engineering} (Item 20 in Appendix \ref{checklist_for_case_studies}).

Furthermore, for each research question the following schema is used. Firstly, they contain results yielded by the thematic analysis performed on archival records. Subsequently, for each relevant theme, they report the validation results obtained through semi-structured interviews described in section \ref{sec:semi-structured_interviews} or, where possible, results obtained through quantitative metrics.

\section{Research Question 1}

As defined in the Introduction chapter, the goal of this Research Question is to evaluate which aspects of Source Code decay are applicable to the Test code. The first phase of the study inspected the available documentation and meta-documentation sources in order to define the most relevant problems that, subsequently, have been analyzed through with quantitative metrics and validated through semi structured Interviews.

The thematic analysis revealed the codes listed in Table \ref{tab:themes_rq1}. They are organized as follows:  on the top level there is a global theme that reflects the nature of RQ1. Next, there are two organizing themes that have been individuated during the first polishing of the generated codes and themes. They distinguish between TD items that arise due to modularity problems (e.g.\ single responsibility violations) and issues that instead arise within single statements. 

This structure has been crafted to accommodate those entries that surpass the boundaries of single codes. For instance, the sentence \textit{``the code is hard to follow''} has been attributed to the code \textit{Complex functions} because a reference to a set of statements is explicit (i.e.\ code) and is safe to assume it is not related with code repetitions, but it could also be attributed to \textit{single responsibility violations}. To avoid information loss during the synthesis the author decided that the structure shall allow overlaps between code under the same organizing theme, but not within codes belonging to different ones. 

Finally, Fig. \ref{fig:rq1_sources} reports the number of sources linked to the specific code and from which of the data source they originate from. Duplicates, like the example reported above, have been counted multiple times. The \textit{mentions}, however, are not weighted since the purpose of the figure \ref{fig:rq1_sources} is to inform the reader of what TD item is more common in the Company.

\begin{table}[!htbp]
\renewcommand{\arraystretch}{1.5}
\centering
\begin{tabular}{ c p{4.3cm} p{4.6cm}}

    \hline
    {\large Global Theme} & {\large Organizing Theme} & {\large Codes}\\
    \hline

    \multirow{4}{*}{\parbox[t]{4.3cm}{
        Source code bad habits that also arise in Test code}
    } & \multirow{2}{*}{\parbox[t]{4.3cm}{Modularity related issues}}
        & Complex functions \\
        & & DRY violations\\
        & & Single responsibility violations\\ \cline{2-3}

    & \multirow{2}{*}{\parbox[t]{4.6cm}{Line related issues}}
        & Complex statements \\
        & & Arity problems \\
    \hline
\end{tabular}
\caption{Themes and codes related to RQ1 generated from thematic analysis}
\label{tab:themes_rq1}
\end{table}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth,keepaspectratio]{figure/results/rq1/sources.pdf}
    \caption[Number of mentions for codes related to RQ1]{Number of mentions for codes related to RQ1 divided by the data source from which an entry has been generated.}
    \label{fig:rq1_sources}
\end{figure}



\subsection{DRY violations}
    The DRY principle stands for \textit{``Don't Repeat Yourself''} and indicates the best practice of factoring out common logic in a separate entity to enhance code reuse.

    Violation of this principle can be due several reasons and tends to greatly impact the maintainability efforts of the code base since a modification must be propagated throughout the code base a number of times equal to the number of copies of the logic interested.

    However, considering the richness of the scripting language provided by UFT, there is more than one way to achieve the same end result and therefore static analysis on the source code was not applicable. It would need algorithms able to inspect the semantic of the code itself to see if the logic a chunk of code describes is the same compared to another one. Developing such tool is outside the scope of this study; furthermore, the author lacked the necessary computational power to execute said tool. For this reasons, only manual analysis of the repositories was used to create findings that have been validated through semi-structured interviews. This inquiry revealed that DRY violations occur on at least three levels. Namely \textit{within a single repository}, \textit{within a single project}, and \textit{between projects}.
    

\subsection{Function complexity}
    The metric used to evaluate this Technical Debt Item is the well know cyclomatic complexity proposed by McCabe \cite{cyclomatic_complexity}.

    Figure \ref{fig:avg-complexity-together} shows the result for all the four projects under study for this metric. On the X-axis revision index that marks the subsequent revision in the source version control. Therefore, it represent a relative time unit. The ordinates' axis instead report the value of the \textit{average} cyclomatic complexity at function level.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth,keepaspectratio]{figure/results/rq1/avg-complexity-together.pdf}
    \caption{Evolution of cyclomatic complexity in studied projects over time.}
    \label{fig:avg-complexity-together}
\end{figure}


\subsection{Single responsibility violations}
    Single responsibility violations are the problems that arise whenever a logical entity, e.g.\ functions, exceeds its logical boundaries and hence incorporates logic that in an optimal solution would be placed in other logical constructs.

    Given the richness of the UFT scripting language a static analysis of the code base was not possible. In fact, it would require advance analysis techniques that use semantics of constructs and varaibles  and function names. This was outside the boundaries of this Thesis work. Therefore, the inquiry, whose results are discussed in section \ref{sec:res-single-responsability-vilation}, is more qualitative and highlights the perception developers have when dealing with source code polluted with this TD item.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth,keepaspectratio]{figure/results/rq1/avg-length-together.pdf}
    \caption{Evolution of average function length in studied projects over time.}
    \label{fig:avg-length-together}
\end{figure}


\subsection{Complex statements}
This problem arises when the code includes statements that execute several operations at once. As steted by Stemlos et al.\ \cite{metrics_source_code}, a high number of such statements hinders understandability and readability of the code base.

A common accepted threshold to identify a statement too \textit{complex} is based on the number of characters used in a line. In scripting languages a number greater that eighty is considered too high; statements should line wrapped or be broken down in several sub-statements with the help of variables.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth,keepaspectratio]{figure/results/rq1/perc-complex-statements.pdf}
    \caption{Evolution of the percentage of complex statements in studied projects over time.}
    \label{fig:perc-complex-statements}
\end{figure}

\subsection{Arity problems}
Arity is the technical term indicating the number of input operands a function takes. A higher number is often related with reduced readability and maintainability of the source code. As it is possible to see from Fig.\ \ref{fig:rq1_sources}, this particular TD item has been mentioned only within the code comments within the repositories.

Moreover, since the related work didn't propose a suitable metric needed to identify the amount of TD associated with this item, the inquiry conducted was solely based on the two validating interviews. Results associated with this particular TD item are described in Section \ref{sec:disc-high-arity}.


\FloatBarrier

\section{Research Question 2}
%
The scope of User Interface tests is to validate the state of the User Interface after a predefined series of actions occurred. However, this entails a different use for the constructs compared to conventional source code and possibly new ones specific for these use cases. For this reason RQ 2 will inspect these unique items.

As for RQ1, the thematic analysis revealed the codes listed in Table \ref{tab:themes_rq2}. The structure is very similar to table \ref{tab:themes_rq1} and the same considerations apply. 

They are organized as follows: on the top level there is a global theme that reflects the nature of RQ2. Next, there are two organizing themes that have been individuated during the first polishing of the generated codes and themes. They distinguish between testing technology problems (i.e.\ problems that could arise with every testing framework that uses said technologies) and issues that are, to the best of the author's knowledge, UFT specific.

\begin{table}
\renewcommand{\arraystretch}{1.5}
\centering
\begin{tabular}{ c p{4.3cm} p{4.6cm}}

    \hline
    {\large Global Theme} & {\large Organizing Theme} & {\large Codes}\\
    \hline

    \multirow{7}{*}{\parbox[b]{4.3cm}{
        User interface testware specific issues
    }
    } & \multirow{4}{*}{\parbox[c]{4.3cm}{Use of wrong UI technology}}
        & IRT: Too sensitive \\
        & & IRT: False positive and negative results\\
        & & IRT: Not reusable\\
        & & IRT: Not suitable for responsive environments (e.g. web applications)\\ 
        & & PBT: Impossible to foresee when it will break\\
        & & CBT: Too fragile\\ \cline{2-3}

    & UFT specific problems & Based on binary files\\

    \hline
\end{tabular}
\caption[Themes and codes related to RQ1 generated from thematic analysis.]{Themes and codes related to RQ1 generated from thematic analysis. \textbf{IRT} means image recognition technology, \textbf{PBT} means property based technology, and \textbf{CBT} mean coordinates based technology}.
\label{tab:themes_rq2}
\end{table}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth,keepaspectratio]{figure/results/rq2/sources.png}
    \caption{Codes with relatives Data sources for research question 2}
    \label{fig:rq2_sources}
\end{figure}


\subsection{Use of wrong UI testing technology}
As displayed in Figure \ref{fig:rq2_sources}, the use of wron UI testing technology is the problem mentioned the most, with numerous references in all the data-soruces used. However, not all the entries point to a problem with a particular one of the testing technologies offered by UFT. Therefore, the author decided to break down this TD item in three sub-items that match the structure. Table \ref{tab:themes_rq2} shows the themes and codes created.
Finally, also the results will tackle this source of TD in a similar manner.


\subsection{Monolithic objects’ database}
UFT offers the functionality of saving cohordinates, object properties, and images in file that must be included in the source version control (SVC) in order for the test to run on any machine. However, this data is stored in a binary file database and, notoriously, SVCs tend to having problem merging conflicting binary files, which result in one of the concurrent versions to be overwritten. As Fig. \ref{fig:rq2_sources} shows, the problem is well-mentioned and recognized by the Company's testers.

\section{Research Question 3}
As mentioned before, the goal of this research question is to evaluate the impact of the Technical Debts items identified in RQ 1 and 2. However, considering the exploratory nature of this Thesis work and the scarcity of resources, results are reported in Table \ref{tab:interest_magnitude} using a normal Likert's scale \cite{likert-scale}. The table includes the interviewee ID, the grade assigned and for each item the average calculated.

\begin{table}[!htbp]
	\centering
	\tabulinesep=1.2mm
	\begin{tabu} to \textwidth {|X[2]|X|X|X|}

		\hline
		\textbf{TD item} & \textbf{Interviewee 3} & \textbf{Interviewee 4}  & \textbf{Average} \\
		\hline

		Function complexity & 3 & 5 & 4 \\
		\hline

		DRY violations & 4 & 5 & 4,5 \\
		\hline

		God Functions & 3 & 4 & 3,5 \\
		\hline

		Complex statements & 3 & 3 & 3 \\
		\hline

		High Arity & 2 & 2 & 2 \\
		\hline

		Image based tests & 3 & 4 & 3,5 \\
		\hline

		Property based tests & 2 & 2 & 2 \\
		\hline

		Coordinates based tests & 4 & 5 & 4,5 \\
		\hline

	\end{tabu}
	\caption{Interest magnitude as perceived by interviewees.}
	\label{tab:interest_magnitude}
\end{table}


